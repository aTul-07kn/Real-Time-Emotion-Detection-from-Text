{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-26T09:26:57.177374Z",
          "iopub.status.busy": "2024-01-26T09:26:57.176507Z",
          "iopub.status.idle": "2024-01-26T09:26:58.716161Z",
          "shell.execute_reply": "2024-01-26T09:26:58.715021Z",
          "shell.execute_reply.started": "2024-01-26T09:26:57.177336Z"
        },
        "id": "kx0pa3pSGICd",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Importing the required libraries\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from keras.models import Sequential,Model\n",
        "from keras.layers import Dense,Bidirectional\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eq3p5LMYGICd"
      },
      "source": [
        "# Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xo0kpYlFGICe",
        "outputId": "fa59726c-25a9-48b0-efa1-746e5c399803",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of rows with sentiment 'anger': 1701\n",
            "Number of rows with sentiment 'fear': 2252\n",
            "Number of rows with sentiment 'joy': 1616\n",
            "Number of rows with sentiment 'sadness': 1533\n"
          ]
        }
      ],
      "source": [
        "df=pd.read_csv('eng_dataset.csv')\n",
        "df.head()\n",
        "anger_count = len(df[df['sentiment'] == 'anger'])\n",
        "fear_count = len(df[df['sentiment'] == 'fear'])\n",
        "joy_count = len(df[df['sentiment'] == 'joy'])\n",
        "sadness_count = len(df[df['sentiment'] == 'sadness'])\n",
        "\n",
        "print(\"Number of rows with sentiment 'anger':\", anger_count)\n",
        "\n",
        "print(\"Number of rows with sentiment 'fear':\", fear_count)\n",
        "\n",
        "print(\"Number of rows with sentiment 'joy':\", joy_count)\n",
        "\n",
        "print(\"Number of rows with sentiment 'sadness':\", sadness_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "Yj16skAfGICf",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "Sentences = df['content']\n",
        "Sentiments = df['sentiment']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ry1-L_0kGICf",
        "outputId": "4a138431-9005-4435-a130-3b70e238850b",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(7102, {'anger', 'fear', 'joy', 'sadness'})"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(Sentences), set(Sentiments)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ga-NkQ_nOY37",
        "outputId": "90e06767-568e-433d-ccf6-9171582ebc3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0         anger\n",
            "1         anger\n",
            "2         anger\n",
            "3         anger\n",
            "4         anger\n",
            "         ...   \n",
            "7097    sadness\n",
            "7098    sadness\n",
            "7099    sadness\n",
            "7100    sadness\n",
            "7101    sadness\n",
            "Name: sentiment, Length: 7102, dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(Sentiments)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjGjVePmGICf"
      },
      "source": [
        "# Load the Glove Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "vsF9l2nnGICg",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "glove ='glove.6B.50d.txt'\n",
        "\n",
        "def load_glove_embeddings(path):\n",
        "    embeddings_index = {}\n",
        "    with open(path, 'r', encoding='utf8') as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            coefs = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings_index[word] = coefs\n",
        "    return embeddings_index\n",
        "\n",
        "Glove = load_glove_embeddings(glove)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "8jTafgH9GICg",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def cosine_similarity(a, b):\n",
        "    \"\"\"\n",
        "    Computes the cosine similarity between two vectors a and b.\n",
        "    \"\"\"\n",
        "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7d3K7rPGICg"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "i8RY_CjPGICg",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# it is removing special characters and also creating tokens\n",
        "def preprocess(Sentences):\n",
        "    sentences = tf.strings.substr(Sentences, 0, 300)\n",
        "    sentences = tf.strings.regex_replace(sentences, b\"<br\\\\s*/?>\", b\" \")\n",
        "    sentences = tf.strings.regex_replace(sentences, b\"[^a-zA-Z']\", b\" \")\n",
        "    sentences = tf.strings.split(sentences)\n",
        "    sentences = tf.strings.lower(sentences)\n",
        "    sentences = sentences.to_tensor(default_value=b\"<pad>\")\n",
        "    return sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8ARt5BDGICh",
        "outputId": "7857939c-3d31-459a-e5f3-6ebba8a6c892",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([7102, 34])"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentences = preprocess(Sentences)\n",
        "sentences.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjHhqLviGICh"
      },
      "source": [
        "# Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "0FDRo4O7GICh",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def encoding(sentences, Glove):\n",
        "    Encoded_vec = []\n",
        "    for sentence in sentences:\n",
        "        sent_vec = []\n",
        "        for token in sentence:\n",
        "            token = token.numpy().decode('utf-8')\n",
        "            if token in Glove:\n",
        "                sent_vec.append(Glove[token])\n",
        "            else:\n",
        "                sent_vec.append(np.zeros(50))\n",
        "        Encoded_vec.append(sent_vec)\n",
        "    return Encoded_vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlCIgfhVGICh",
        "outputId": "f635f414-d6b1-49d5-a744-647c5a0bd877",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(7102, 34, 50)\n"
          ]
        }
      ],
      "source": [
        "Encoded_vec = encoding(sentences, Glove)\n",
        "X = np.array(Encoded_vec)\n",
        "print(X.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8EptQ4vGICh"
      },
      "source": [
        "# One-hot Encoding of target sentiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozVa3kDvGICh",
        "outputId": "d102bca3-8d21-4771-c9cb-a2c144082f80",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(7102, 4)\n"
          ]
        }
      ],
      "source": [
        "# Perform one-hot encoding on df[0] i.e emotion\n",
        "enc = OneHotEncoder(handle_unknown='ignore')\n",
        "Y = enc.fit_transform(np.array(Sentiments).reshape(-1,1)).toarray()\n",
        "print(Y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1k0vk3sGICi"
      },
      "source": [
        "# Split the train & test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wu-Ziq6XGICi",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Split into train and test\n",
        "from keras.layers import Embedding\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=23)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "0SVi935FXrOH",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#Defining the BiLSTM Model\n",
        "class BiLSTMModel:\n",
        "    def __init__(self):\n",
        "        self.model = Sequential()\n",
        "        self.model.add(Bidirectional(LSTM(100, input_shape=(100, 50))))\n",
        "        self.model.add(Dropout(0.2))\n",
        "        self.model.add(Dense(4, activation='softmax'))\n",
        "        self.model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    def fit(self, X, Y, epochs, batch_size):\n",
        "        self.model.fit(X, Y, epochs=epochs, batch_size=batch_size)\n",
        "\n",
        "    def evaluate(self, X, Y, batch_size):\n",
        "        return self.model.evaluate(X, Y, batch_size=batch_size)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.model.predict(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "KfwX3Bw-Hiq0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem.lancaster import LancasterStemmer\n",
        "import nltk\n",
        "import re\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, GRU, LSTM, Bidirectional, Embedding, Dropout\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from livelossplot.tf_keras import PlotLossesCallback\n",
        "from livelossplot import PlotLossesKeras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOYUSNtYGICi"
      },
      "source": [
        "# Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lv9WsV7jX97J",
        "outputId": "7c5e4797-3a33-4db0-a2d1-68ae5590a820",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "89/89 [==============================] - 14s 99ms/step - loss: 1.3095 - accuracy: 0.3737\n",
            "Epoch 2/50\n",
            "89/89 [==============================] - 8s 88ms/step - loss: 1.1237 - accuracy: 0.5040\n",
            "Epoch 3/50\n",
            "89/89 [==============================] - 9s 95ms/step - loss: 1.0179 - accuracy: 0.5735\n",
            "Epoch 4/50\n",
            "89/89 [==============================] - 9s 100ms/step - loss: 0.9283 - accuracy: 0.6170\n",
            "Epoch 5/50\n",
            "89/89 [==============================] - 9s 96ms/step - loss: 0.8275 - accuracy: 0.6710\n",
            "Epoch 6/50\n",
            "89/89 [==============================] - 8s 90ms/step - loss: 0.7382 - accuracy: 0.7115\n",
            "Epoch 7/50\n",
            "89/89 [==============================] - 9s 100ms/step - loss: 0.6551 - accuracy: 0.7502\n",
            "Epoch 8/50\n",
            "89/89 [==============================] - 9s 98ms/step - loss: 0.5900 - accuracy: 0.7780\n",
            "Epoch 9/50\n",
            "89/89 [==============================] - 8s 88ms/step - loss: 0.5342 - accuracy: 0.7992\n",
            "Epoch 10/50\n",
            "89/89 [==============================] - 9s 100ms/step - loss: 0.4808 - accuracy: 0.8205\n",
            "Epoch 11/50\n",
            "89/89 [==============================] - 9s 100ms/step - loss: 0.4296 - accuracy: 0.8419\n",
            "Epoch 12/50\n",
            "89/89 [==============================] - 8s 86ms/step - loss: 0.3886 - accuracy: 0.8597\n",
            "Epoch 13/50\n",
            "89/89 [==============================] - 9s 100ms/step - loss: 0.3601 - accuracy: 0.8697\n",
            "Epoch 14/50\n",
            "89/89 [==============================] - 9s 100ms/step - loss: 0.3158 - accuracy: 0.8861\n",
            "Epoch 15/50\n",
            "89/89 [==============================] - 8s 85ms/step - loss: 0.2857 - accuracy: 0.8923\n",
            "Epoch 16/50\n",
            "89/89 [==============================] - 9s 99ms/step - loss: 0.2471 - accuracy: 0.9113\n",
            "Epoch 17/50\n",
            "89/89 [==============================] - 9s 99ms/step - loss: 0.2432 - accuracy: 0.9113\n",
            "Epoch 18/50\n",
            "89/89 [==============================] - 8s 85ms/step - loss: 0.2169 - accuracy: 0.9245\n",
            "Epoch 19/50\n",
            "89/89 [==============================] - 9s 100ms/step - loss: 0.2177 - accuracy: 0.9180\n",
            "Epoch 20/50\n",
            "89/89 [==============================] - 9s 100ms/step - loss: 0.1991 - accuracy: 0.9241\n",
            "Epoch 21/50\n",
            "89/89 [==============================] - 8s 86ms/step - loss: 0.1633 - accuracy: 0.9377\n",
            "Epoch 22/50\n",
            "89/89 [==============================] - 9s 99ms/step - loss: 0.1482 - accuracy: 0.9454\n",
            "Epoch 23/50\n",
            "89/89 [==============================] - 9s 100ms/step - loss: 0.1245 - accuracy: 0.9532\n",
            "Epoch 24/50\n",
            "89/89 [==============================] - 8s 86ms/step - loss: 0.1202 - accuracy: 0.9562\n",
            "Epoch 25/50\n",
            "89/89 [==============================] - 9s 99ms/step - loss: 0.1378 - accuracy: 0.9479\n",
            "Epoch 26/50\n",
            "89/89 [==============================] - 9s 99ms/step - loss: 0.1246 - accuracy: 0.9505\n",
            "Epoch 27/50\n",
            "89/89 [==============================] - 8s 86ms/step - loss: 0.1396 - accuracy: 0.9446\n",
            "Epoch 28/50\n",
            "89/89 [==============================] - 9s 99ms/step - loss: 0.1145 - accuracy: 0.9528\n",
            "Epoch 29/50\n",
            "89/89 [==============================] - 9s 102ms/step - loss: 0.0875 - accuracy: 0.9644\n",
            "Epoch 30/50\n",
            "89/89 [==============================] - 8s 87ms/step - loss: 0.0964 - accuracy: 0.9593\n",
            "Epoch 31/50\n",
            "89/89 [==============================] - 9s 100ms/step - loss: 0.1046 - accuracy: 0.9579\n",
            "Epoch 32/50\n",
            "89/89 [==============================] - 9s 100ms/step - loss: 0.0947 - accuracy: 0.9611\n",
            "Epoch 33/50\n",
            "89/89 [==============================] - 8s 87ms/step - loss: 0.1008 - accuracy: 0.9588\n",
            "Epoch 34/50\n",
            "89/89 [==============================] - 9s 100ms/step - loss: 0.1562 - accuracy: 0.9421\n",
            "Epoch 35/50\n",
            "89/89 [==============================] - 9s 100ms/step - loss: 0.0961 - accuracy: 0.9599\n",
            "Epoch 36/50\n",
            "89/89 [==============================] - 8s 87ms/step - loss: 0.0821 - accuracy: 0.9636\n",
            "Epoch 37/50\n",
            "89/89 [==============================] - 9s 100ms/step - loss: 0.0800 - accuracy: 0.9657\n",
            "Epoch 38/50\n",
            "89/89 [==============================] - 9s 100ms/step - loss: 0.0775 - accuracy: 0.9660\n",
            "Epoch 39/50\n",
            "89/89 [==============================] - 8s 86ms/step - loss: 0.0716 - accuracy: 0.9687\n",
            "Epoch 40/50\n",
            "89/89 [==============================] - 9s 100ms/step - loss: 0.0622 - accuracy: 0.9711\n",
            "Epoch 41/50\n",
            "89/89 [==============================] - 9s 101ms/step - loss: 0.0736 - accuracy: 0.9680\n",
            "Epoch 42/50\n",
            "89/89 [==============================] - 8s 90ms/step - loss: 0.0764 - accuracy: 0.9641\n",
            "Epoch 43/50\n",
            "89/89 [==============================] - 9s 96ms/step - loss: 0.1241 - accuracy: 0.9511\n",
            "Epoch 44/50\n",
            "89/89 [==============================] - 9s 99ms/step - loss: 0.1023 - accuracy: 0.9570\n",
            "Epoch 45/50\n",
            "89/89 [==============================] - 8s 90ms/step - loss: 0.0904 - accuracy: 0.9618\n",
            "Epoch 46/50\n",
            "89/89 [==============================] - 9s 95ms/step - loss: 0.0760 - accuracy: 0.9662\n",
            "Epoch 47/50\n",
            "89/89 [==============================] - 9s 101ms/step - loss: 0.0706 - accuracy: 0.9676\n",
            "Epoch 48/50\n",
            "89/89 [==============================] - 8s 94ms/step - loss: 0.0630 - accuracy: 0.9678\n",
            "Epoch 49/50\n",
            "89/89 [==============================] - 8s 92ms/step - loss: 0.0639 - accuracy: 0.9699\n",
            "Epoch 50/50\n",
            "89/89 [==============================] - 9s 100ms/step - loss: 0.0640 - accuracy: 0.9692\n"
          ]
        }
      ],
      "source": [
        "# create an instance of the BiLSTMModel class\n",
        "model = BiLSTMModel()\n",
        "hist = model.fit(X_train, Y_train,\n",
        "                 epochs = 50,\n",
        "                 batch_size = 64)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsXRfGJ3YMoq",
        "outputId": "a43728ec-b144-484d-965f-f49a82d87625",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_2 (Bidirectio  (None, 200)              120800    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 200)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 4)                 804       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 121,604\n",
            "Trainable params: 121,604\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjWFx-rzGICi"
      },
      "source": [
        "# Evaluations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d7QWxXtUMCN",
        "outputId": "61207ff1-1625-41c3-9104-a0a3e24f1904",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "23/23 [==============================] - 2s 60ms/step - loss: 1.0719 - accuracy: 0.7741\n",
            "Loss: 1.07\n",
            "acc: 0.77\n"
          ]
        }
      ],
      "source": [
        "Loss, acc = model.evaluate(X_test, Y_test, batch_size=64)\n",
        "print(\"Loss: %.2f\" % (Loss))\n",
        "print(\"acc: %.2f\" % (acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAS5VhKqGICj"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uthwmnkI_cbr",
        "outputId": "af70685a-f1d9-4a8d-a817-84561edaf992"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter : hey i am feeling good\n",
            "(1, 5, 50)\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "fear\n",
            "Enter : it feels great\n",
            "(1, 3, 50)\n",
            "1/1 [==============================] - 1s 798ms/step\n",
            "sadness\n",
            "Enter : i am happy for you\n",
            "(1, 5, 50)\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "joy\n",
            "Enter : See its a sunny day\n",
            "(1, 5, 50)\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "joy\n",
            "Enter : This is the most useless product\n",
            "(1, 6, 50)\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "fear\n",
            "Enter : \n",
            "(1, 0)\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 2169, in predict_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 2155, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 2143, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 2111, in predict_step\n        return self(x, training=False)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    ValueError: Exception encountered when calling layer 'sequential_2' (type Sequential).\n    \n    Cannot iterate over a shape with unknown rank.\n    \n    Call arguments received by layer 'sequential_2' (type Sequential):\n      • inputs=tf.Tensor(shape=<unknown>, dtype=float32)\n      • training=False\n      • mask=None\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-110-eba973a5c207>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTwt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0;31m#Predict the sentiment by passing the sentence to the model we built.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m   \u001b[0msentiment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTwt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m   \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentiment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategories_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-103-49ecfbca67e4>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__predict_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 2169, in predict_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 2155, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 2143, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 2111, in predict_step\n        return self(x, training=False)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    ValueError: Exception encountered when calling layer 'sequential_2' (type Sequential).\n    \n    Cannot iterate over a shape with unknown rank.\n    \n    Call arguments received by layer 'sequential_2' (type Sequential):\n      • inputs=tf.Tensor(shape=<unknown>, dtype=float32)\n      • training=False\n      • mask=None\n"
          ]
        }
      ],
      "source": [
        "#First, initialize it.\n",
        "while True:\n",
        "\n",
        "  i=input(\"Enter : \")\n",
        "  twt = [i]\n",
        "  #Next, tokenize it.\n",
        "  Twt = preprocess(twt)\n",
        "\n",
        "  # Encoding\n",
        "  Twt = encoding(Twt, Glove)\n",
        "  Twt = np.array(Twt)\n",
        "  print(Twt.shape)\n",
        "  #Predict the sentiment by passing the sentence to the model we built.\n",
        "  sentiment = model.predict(Twt)[0]\n",
        "  label = np.argmax(sentiment)\n",
        "  print(enc.categories_[0][label])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "JWZ3y1ye_l42"
      },
      "outputs": [],
      "source": [
        "model.model.save('trained_model_3.h5')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "tpu1vmV38",
      "dataSources": [
        {
          "datasetId": 8542,
          "sourceId": 11957,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 710787,
          "sourceId": 1239644,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30446,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
